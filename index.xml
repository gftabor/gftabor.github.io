<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Griffin Tabor</title>
    <link>https://gftabor.github.io/</link>
      <atom:link href="https://gftabor.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Griffin Tabor</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 29 Jul 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://gftabor.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Griffin Tabor</title>
      <link>https://gftabor.github.io/</link>
    </image>
    
    <item>
      <title>Attracting Conductive Nonmagnetic Objects With Rotating Magnetic Dipole Fields </title>
      <link>https://gftabor.github.io/publication/devin-ral/</link>
      <pubDate>Fri, 29 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/publication/devin-ral/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adaptive Manipulation of Conductive, Nonmagnetic Objects via a Continuous Model of Magnetically Induced Force and Torque</title>
      <link>https://gftabor.github.io/publication/rss/</link>
      <pubDate>Mon, 27 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/publication/rss/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/SO8RpAspmQA&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Ll4ma Optimization Package</title>
      <link>https://gftabor.github.io/project/ll4ma_opt/</link>
      <pubDate>Thu, 18 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/project/ll4ma_opt/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Dexterous magnetic manipulation of conductive non-magnetic objects</title>
      <link>https://gftabor.github.io/publication/nature/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/publication/nature/</guid>
      <description>
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/QPlV1K-zT0Q&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>PathWeaver</title>
      <link>https://gftabor.github.io/project/pathweaver-wpilib/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/project/pathweaver-wpilib/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://gftabor.github.io/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Autonomous VEX Robotics Competition</title>
      <link>https://gftabor.github.io/project/autonomous-vex-robotics/</link>
      <pubDate>Tue, 18 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/project/autonomous-vex-robotics/</guid>
      <description>&lt;p&gt;The VEX Robotics University competition is a competition where colleges build robots to play a sport. These robots run preengineered actions for the first minute and then have a minute of driver control. I led undergraduate team attempting to compete with a robot running autonomously for the entire 2 minute competition. Making its own decisions during both traditionally hand scripted section and the driver control section.&lt;/p&gt;
&lt;p&gt;In 2017 we competed with a fully integrated robotics stack running autonomously at the world championship. Seen below is one of our best matches from the world championship. The event was full of bugs causing the robot to stop working and when it did work perfectly lots of suboptimal behavior that unsurprisingly resulted in losing against human drivers.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/0ATOqS8XGKY&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;The autonomy elements were built on a 150$ budget using a simple planar lidar, raspberry pi and a set of encoders. The software stack was built using &lt;a href=&#34;https://www.ros.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ROS&lt;/a&gt; and &lt;a href=&#34;https://pointclouds.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PCL&lt;/a&gt;. The software is entirely &lt;a href=&#34;https://github.com/Team-Optimistic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;open source&lt;/a&gt; and was released to the community in the hopes it would spure others to be interest in autonomy.&lt;/p&gt;
&lt;p&gt;In 2018 we decided to upgrade the entire stack to encorporate state of the art tools instead of handbuilt pieces, this would also serve as my senior thesis project. For example we replaced open loop dead reckoning with &lt;a href=&#34;https://opensource.google/projects/cartographer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Google Cartographer&lt;/a&gt; a slam package to map the field and then be switched to pure mapping during runtime. We used the &lt;a href=&#34;http://wiki.ros.org/navigation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ROS Nav Stack&lt;/a&gt; instead of simple drive straight turn in place motion commands like in 2017, so we could more properly handle robot collisions with walls instead of an overly cautious hack. Below is a video of our demo robotic platform running SLAM and Nav Stack motion planning running a script of high level commands.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/LJo8Q0LNF6I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;We also replaced our hand built very hacky pointcloud based objet classifier with state of the art computer vision CNN running on an onboard GPU. Example below showing some of our hand labeled dataset collected on our demo platform of the robot driving around while recording our pair of fisheye cameras. The fisheye camera is pointing downwards and &amp;ldquo;unwrapped&amp;rdquo; so that angle of the original image is represented as x axis in our new image and the pixel distance from the calibrated camera sensor is the y axis in the new image. This meant that a single image covered a large FOV and that objects in front vs behind looked the same to our neural network that would not normally be rotationally invariant.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://gftabor.github.io/uploads/dataset.gif&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;While this updated system was never fully integrated it was a good demonstration of what was possible given standard tools onboard the robot given various constraints like space and power consumption. This project won the WPI Provost award in the Computer Science Department. Excitingly since this project VEX Robotics Competition has added a &lt;a href=&#34;https://www.vexrobotics.com/v5/competition/vex-ai?q=&amp;amp;locale.name=English&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;special division&lt;/a&gt; for teams attempting to develop autonomous robots.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://gftabor.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://gftabor.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
